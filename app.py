# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nFL3yikDPLKi6llccEKbZfz1qVLIDF5f
"""

import os
import json
import tempfile

import joblib
import numpy as np
import pandas as pd
import streamlit as st
import librosa
import librosa.display
import matplotlib.pyplot as plt
import tensorflow as tf

# ---------- Paths ----------

ARTIFACTS_DIR = "artifacts"
DATA_AUDIO_DIR = os.path.join("data", "voiced")  # put VOICED *.txt files here

MODEL_PATH = os.path.join(ARTIFACTS_DIR, "voiced_model.keras")
SCALER_PATH = os.path.join(ARTIFACTS_DIR, "scaler.joblib")
OHE_PATH = os.path.join(ARTIFACTS_DIR, "onehot_encoder.joblib")
DX_ENCODER_PATH = os.path.join(ARTIFACTS_DIR, "dx_encoder.joblib")
META_JSON_PATH = os.path.join(ARTIFACTS_DIR, "meta.json")
METADATA_CSV_PATH = os.path.join(ARTIFACTS_DIR, "metadata.csv")

# ---------- Load artifacts ----------

@st.cache_resource
def load_artifacts():
    # Model
    model = tf.keras.models.load_model(MODEL_PATH)

    # Scalers / encoders
    scaler = joblib.load(SCALER_PATH)
    onehot_encoder = joblib.load(OHE_PATH)
    dx_encoder = joblib.load(DX_ENCODER_PATH)

    # Meta
    with open(META_JSON_PATH, "r") as f:
        meta = json.load(f)

    # Metadata dataframe
    metadata_df = pd.read_csv(METADATA_CSV_PATH)

    numerical_cols = meta["numerical_cols"]
    categorical_cols = meta["categorical_cols"]
    top_diagnoses = meta["top_diagnoses"]

    return (
        model,
        scaler,
        onehot_encoder,
        dx_encoder,
        metadata_df,
        numerical_cols,
        categorical_cols,
        top_diagnoses,
        meta,
    )


(
    model,
    scaler,
    onehot_encoder,
    dx_encoder,
    metadata_df,
    numerical_cols,
    categorical_cols,
    TOP_DIAGNOSES,
    meta,
) = load_artifacts()

SR = meta["sample_rate"]
N_MFCC = meta["n_mfcc"]
N_FFT = meta["n_fft"]
HOP_LENGTH = meta["hop_length"]


# ---------- Helpers: audio + features + plotting ----------

def load_wave_from_txt(txt_path, sr=SR):
    """
    Load waveform from VOICED .txt file (one sample per line).
    """
    y = np.loadtxt(txt_path, dtype=float)
    # Ensure float32 for librosa compatibility
    return y.astype(np.float32), sr


def extract_mfcc_features(y, sr=SR):
    """
    Extract mean MFCC vector using the same parameters as training.
    """
    mfccs = librosa.feature.mfcc(
        y=y, sr=sr, n_mfcc=N_MFCC, n_fft=N_FFT, hop_length=HOP_LENGTH
    )
    # Mean over time axis -> shape (N_MFCC,)
    return mfccs.mean(axis=1)


def plot_spectrogram(y, sr=SR):
    """
    Return a matplotlib figure with a Mel spectrogram.
    """
    S = librosa.feature.melspectrogram(
        y=y, sr=sr, n_fft=N_FFT, hop_length=HOP_LENGTH
    )
    S_db = librosa.power_to_db(S, ref=np.max)

    fig, ax = plt.subplots(figsize=(6, 4))
    img = librosa.display.specshow(
        S_db,
        sr=sr,
        hop_length=HOP_LENGTH,
        x_axis="time",
        y_axis="mel",
        ax=ax,
    )
    ax.set_title("Mel Spectrogram")
    fig.colorbar(img, ax=ax, format="%+2.0f dB")
    return fig


# ---------- Build model input row from MFCC vector ----------

# Precompute medians/modes on the training distribution approximated by metadata_df
# (For numerical placeholders we only really have age, vhi_score, rsi_score here;
# the rest of the columns used during training are given default medians.)
UNSCALED_NUMERIC_MEDIANS = {}
for col in numerical_cols:
    if col in metadata_df.columns:
        UNSCALED_NUMERIC_MEDIANS[col] = float(metadata_df[col].median())
    else:
        # Reasonable neutral default
        UNSCALED_NUMERIC_MEDIANS[col] = 0.0

CATEGORICAL_MODES = {}
for col in categorical_cols:
    if col in metadata_df.columns:
        CATEGORICAL_MODES[col] = metadata_df[col].mode().iloc[0]
    else:
        CATEGORICAL_MODES[col] = "unknown"


def build_model_input_from_mfcc(mfcc_vector):
    """
    Given an MFCC mean vector, build a single-row feature matrix
    that matches X_processed used in training:
    - scaled numerical features
    - one-hot encoded categorical features
    """
    # ----- 1. Numerical dataframe -----
    num_df = pd.DataFrame(columns=numerical_cols, index=[0])

    # Fill MFCC_* columns
    for i in range(len(mfcc_vector)):
        col = f"mfcc_{i+1}"
        if col in num_df.columns:
            num_df.loc[0, col] = mfcc_vector[i]

    # Fill remaining numerical columns with medians
    for col in numerical_cols:
        if pd.isna(num_df.loc[0, col]):
            num_df.loc[0, col] = UNSCALED_NUMERIC_MEDIANS.get(col, 0.0)

    # Scale numerical features
    num_scaled = scaler.transform(num_df)
    num_scaled_df = pd.DataFrame(num_scaled, columns=numerical_cols, index=[0])

    # ----- 2. Categorical dataframe -----
    cat_df = pd.DataFrame(columns=categorical_cols, index=[0])
    for col in categorical_cols:
        cat_df.loc[0, col] = CATEGORICAL_MODES.get(col, "unknown")

    # One-hot encode categorical
    cat_encoded = onehot_encoder.transform(cat_df)
    cat_encoded_df = pd.DataFrame(
        cat_encoded,
        columns=onehot_encoder.get_feature_names_out(categorical_cols),
        index=[0],
    )

    # ----- 3. Final feature row -----
    X_single = pd.concat([num_scaled_df, cat_encoded_df], axis=1)
    return X_single


def predict_diagnosis_from_mfcc(mfcc_vector):
    """
    Use the trained multi-output model to predict diagnosis,
    given an MFCC mean vector.
    """
    X_single = build_model_input_from_mfcc(mfcc_vector)

    # model outputs: [gender_output, diagnosis_output, age_output, vhi_output, rsi_output]
    preds = model.predict(X_single, verbose=0)
    diagnosis_probs = preds[1][0]  # index 1 = diagnosis_output

    # Decode class names from dx_encoder
    class_names_full = dx_encoder.get_feature_names_out(["diagnosis"])
    # Names look like 'diagnosis_healthy' -> strip prefix
    class_labels_full = [c.replace("diagnosis_", "") for c in class_names_full]

    best_idx = int(np.argmax(diagnosis_probs))
    best_label = class_labels_full[best_idx]
    prob_dict = {
        label: float(diagnosis_probs[i]) for i, label in enumerate(class_labels_full)
    }

    return best_label, prob_dict


# ---------- Streamlit UI ----------

st.set_page_config(
    page_title="VOICED Explorer & Voice Disorder Model",
    layout="wide",
)

st.title("VOICED Dataset Explorer & Voice Disorder Model (Educational)")

st.markdown(
    """
This app lets you:

1. Explore spectrograms of VOICED dataset samples filtered by **gender**, **age**, and **diagnosis**
2. Upload your own voice audio and see how a trained model classifies it

> **Important:** This is for **educational and research purposes only**.
> It is **not** a medical device and must **not** be used for diagnosis or clinical decisions.
"""
)

tab1, tab2 = st.tabs(["Explore VOICED samples", "Upload your voice"])


# =========================
# TAB 1: Dataset exploration
# =========================

with tab1:
    st.subheader("Explore VOICED samples")

    col1, col2, col3 = st.columns(3)
    with col1:
        gender_filter = st.selectbox("Gender", ["Any", "Male", "Female"])
    with col2:
        min_age = int(metadata_df["age"].min())
        max_age = int(metadata_df["age"].max())
        age_range = st.slider("Age range", min_age, max_age, (min_age, max_age))
    with col3:
        # UI focuses on healthy + top-4 pathologies
        condition_options = ["Any", "healthy"] + TOP_DIAGNOSES
        diagnosis_filter = st.selectbox("Diagnosis", condition_options)

    df_filtered = metadata_df.copy()

    # Apply filters
    if gender_filter != "Any":
        # Map 'Male'/'Female' to whatever your labels are ('m'/'f' etc.)
        if gender_filter.lower().startswith("m"):
            df_filtered = df_filtered[df_filtered["gender"].str.lower().str.startswith("m")]
        else:
            df_filtered = df_filtered[df_filtered["gender"].str.lower().str.startswith("f")]

    df_filtered = df_filtered[
        (df_filtered["age"] >= age_range[0]) & (df_filtered["age"] <= age_range[1])
    ]

    if diagnosis_filter != "Any":
        df_filtered = df_filtered[df_filtered["diagnosis"] == diagnosis_filter]

    if len(df_filtered) == 0:
        st.warning("No samples match this filter. Try broadening the age range or changing diagnosis.")
    else:
        sample_ids = df_filtered["ID"].tolist()

        col_a, col_b = st.columns([2, 1])
        with col_a:
            selected_id = st.selectbox("Select a VOICED sample", sample_ids)
        with col_b:
            if st.button("Random sample from filter"):
                import random
                selected_id = random.choice(sample_ids)

        audio_filename = f"{selected_id}.txt"
        audio_path = os.path.join(DATA_AUDIO_DIR, audio_filename)

        if not os.path.exists(audio_path):
            st.error(f"Audio file not found: {audio_path}")
        else:
            y, sr = load_wave_from_txt(audio_path)
            fig = plot_spectrogram(y, sr)
            st.pyplot(fig)

            row = metadata_df[metadata_df["ID"] == selected_id].iloc[0]

            st.markdown("**Sample metadata**")
            st.write(
                {
                    "ID": row["ID"],
                    "Age": row["age"],
                    "Gender": row["gender"],
                    "Diagnosis": row["diagnosis"],
                    "VHI score": row.get("vhi_score", None),
                    "RSI score": row.get("rsi_score", None),
                }
            )

            if st.checkbox("Show model prediction for this sample"):
                mfcc_vec = extract_mfcc_features(y, sr)
                pred_label, prob_dict = predict_diagnosis_from_mfcc(mfcc_vec)

                st.markdown(f"**Model-predicted diagnosis:** {pred_label}")
                st.markdown("**Class probabilities:**")
                st.write(prob_dict)


# =========================
# TAB 2: Upload your voice
# =========================

with tab2:
    st.subheader("Upload your voice (ideally a sustained /a/ vowel)")

    st.markdown(
        """
Upload a short recording of your voice as a `.wav` or `.mp3` file.
The model will:

- compute MFCC features,
- show a spectrogram,
- and predict a diagnosis class.

Again: this is **not** a medical test.
"""
    )

    uploaded_file = st.file_uploader("Upload audio file", type=["wav", "mp3"])

    if uploaded_file is not None:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".tmp") as tmp:
            tmp.write(uploaded_file.getvalue())
            temp_path = tmp.name

        y, sr = librosa.load(temp_path, sr=SR)

        st.markdown("**Spectrogram of your voice**")
        fig_user = plot_spectrogram(y, sr)
        st.pyplot(fig_user)

        mfcc_vec = extract_mfcc_features(y, sr)
        pred_label, prob_dict = predict_diagnosis_from_mfcc(mfcc_vec)

        st.markdown(f"**Model-predicted diagnosis:** {pred_label}")
        st.markdown("**Class probabilities:**")
        st.write(prob_dict)

        st.info(
            "This prediction is generated by a research model trained on the VOICED dataset "
            "and is **not** intended for clinical use."
        )